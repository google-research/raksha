//-----------------------------------------------------------------------------
// Copyright 2022 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//----------------------------------------------------------------------------

// This is a minimal proto targeted at the MVP integration with a Google SQL
// verifier. It's just to push a limited set of constructs across the
// language barrier.
syntax = "proto3";

package raksha.frontends.sql;

// This value corresponds to some column in some source table for the query
// being analyzed.
message SourceTableColumn {
  // The fully-qualified path to the column, including table name and (if it
  // exists) schema name.
  string column_path = 1;
}

// A literal. The SQL verifier currently just passes on the string form of the
// literal as seen by the parser. For the MVP, we just continue passing this
// along.
message Literal {
  string literal_str = 1;
}

// This `MergeOperation` is an all-purpose combination of inputs into a single
// output. Unless indicated by a `TagTransform`, this will always drop all
// `IntegrityTag`s and propagate all `ConfidentialityTag`s.
message MergeOperation {
  // Direct dataflow dependencies. Relevant for confidentiality and integrity
  // tags.
  repeated uint64 inputs = 2;
  // Control dependencies. Confidentiality tags can flow from these inputs to
  // the outputs. They are irrelevant to integrity tags.
  repeated uint64 control_inputs = 3;
}

// A transform upon the tag state of a program.
//
// A `TagTransform` is structured like a cast upon some `transformed_node`
// `Expression`. It takes as input some `transformed_node` expression and 0 or
// more `tag_precondition` expressions, each associated with a name via the
// `map` structure. Each `tag_precondition` expression must be some transitive
// child of the `transformed_node` expression (they need not be direct children
// of that node).
// The `TagTransform` considers whether the `tag_precondition`s have the
// `IntegrityTag`s required for `transform_rule_name` to apply. If the
// preconditions do have the required `IntegrityTag`s, then this `TagTransform`
// shall add or remove tags as specified by the rule corresponding to
// `transform_rule_name` (the details of which are in separate policy datalog).
// If the preconditions are not met, then the `TagTransform` just propagates the
// exact tag state of the `transformed_node`.
message TagTransform {
  // The `Expression` that is having its tag state changed by the
  // `TagTransform`.
  uint64 transformed_node = 1;
  // The name of the rule that will govern whether this `TagTransform` is
  // active and what it does when active.
  string transform_rule_name = 2;
  // A map from precondition names to unique IDs of expressions considered to
  // be preconditions of the `TagTransform`. The names will also be used by
  // the policy to match these tag IDs with the requirements imposed by some
  // rule.
  map<string, uint64> tag_preconditions = 3;
}

message Expression {
  // We may optionally associate expressions with names to help with building
  // `AccessPaths`. This name may include column and/or table aliases provided
  // by the user. It may also include our own auto-generated hints.
  string name = 1;
  // The specific kinds of expressions.
  oneof expr_variant {
    SourceTableColumn source_table_column = 2;
    Literal literal = 3;
    MergeOperation merge_operation = 4;
    TagTransform tag_transform = 5;
  }
}

// An association of an ID and an Expression.
//
// We use a unique ID to "point" from one `Expression` to another. This ID could
// go on the `Expression` itself, but this is somewhat annoying: because it
// isn't part of the useful data of the `Expression`, it is awkward to construct
// and test in some circumstances. Because it is an "address" at which the
// `Expression` resides, it most naturally lives in the "memory" object, the
// `ExpressionArena`. We could use a `map`, but `map`s have no guaranteed order
// in protobufs and we would like pointed-to `Expression`s to come before the
// `Expression`s pointing to them in the wire order. Therefore, we create these
// pairs of id and `Expression` to give a map-like association of keys and
// values with a guaranteed wire order.
message IdExpressionPair {
  uint64 id = 1;
  Expression expression = 2;
}

message SqlPolicyRule {
  message Result {
    enum Action {
      ANY = 0;
      ADD_CONFIDENTIALITY = 1;
      REMOVE_CONFIDENTIALITY = 2;
      ADD_INTEGRITY = 3;
    }
    Action action = 1;
    string tag = 2;
  }

  message Precondition {
    string argument = 1;
    string required_tag = 2;
  }

  string name = 1;
  Result result = 2;
  repeated Precondition preconditions = 3;
}

// An Arena used as the canonical owner of all `Expression`s. `Expression`s will
// "point" to their children via IDs. It's tempting to point to the expressions
// via their positions in the list, but imposing a density requirement on the
// inputs like that can be very constraining on how protos can be generated by
// clients.
//
// It is expected that `Expression`s form a DAG and that `Expression`s only
// point to `Expression`s earlier in the list. This allows us to assume as we
// read `Expression`s off the wire that the children of the current node have
// already been deserialized.
message ExpressionArena {
  repeated IdExpressionPair id_expression_pairs = 1;
  repeated SqlPolicyRule sql_policy_rules = 2;
}
